#Pet Detector code 
# Refering to https://github.com/EdjeElectronics/TensorFlow-Object Detection-on-the-Raspberry-Pi/blob/master/Object_detection_picamera.py # tutorial for using Twilio:  
https://www.twilio.com/docs/sms/quickstart/python 
#------------------- Import packages----------------------# import os 
import cv2 
import numpy as np 
from picamera.array import PiRGBArray 
from picamera import PiCamera 
import tensorflow as tf 
import argparse 
import sys 
import RPi.GPIO as GPIO 
from time import sleep 
GPIO.setwarnings(False) 
GPIO.setmode(GPIO.BOARD) 
#-----------------------Set up Twilio---------------------------# from twilio.rest import Client 
# Twilio SID, authentication token, my phone number, and the Twilio phone  number 
# are stored as environment variables on my Pi so people can't see them account_sid = "ACe43d707047e51ff39324054ece013340" 
auth_token = "d5d7b18e72c43f9bf2e49f8931feb15b" 
my_number = "+821083373376" 
twilio_number = "+17706290942" 
client = Client(account_sid,auth_token) 
#----------------------------Driving Motor-----------------------------# # Set pins 11 & 12 as outputs, and define as PWM servo1 & servo2 
GPIO.setup(11,GPIO.OUT) 
servo1 = GPIO.PWM(11,50) # pin 11 for servo1 
GPIO.setup(12,GPIO.OUT) 
servo2 = GPIO.PWM(12,50) # pin 12 for servo2 
# Start PWM running on both servos, value of 0 (pulse off) servo1.start(0) 
servo2.start(0) 
start_motor=0 
#----------------------- Set up camera constants--------------------------- ----# 
IM_WIDTH = 800 
IM_HEIGHT = 400 
# Select camera type (we are using Pi camera, so delete USB section) camera_type = 'picamera' 
parser = argparse.ArgumentParser()
args = parser.parse_args() 
#------------------------Initialize TensorFlow model----------------------- ------# 
# This is needed since the working directory is the object_detection  folder. 
sys.path.append('..') 
# Import utilites 
from utils import label_map_util 
from utils import visualization_utils as vis_util 
# Name of the directory containing the object detection module we're using # High Accuracy Low Speed 
MODEL_NAME = 'ssdlite_mobilenet_v2_coco_2018_05_09' 
# Grab path to current working directory 
CWD_PATH = os.getcwd() 
# Path to frozen detection graph .pb file, which contains the model that is  used 
# for object detection. 
PATH_TO_CKPT =  
os.path.join(CWD_PATH,MODEL_NAME,'frozen_inference_graph.pb') 
# Path to label map file 
PATH_TO_LABELS = os.path.join(CWD_PATH,'data','mscoco_label_map.pbtxt') 
# Number of classes the object detector can identify 
NUM_CLASSES = 90 
#---------------------- Load the label map & Tensorflow Model-------------- ------------------_# 
# Label maps map indices to category names, so that when the convolution # network predicts `5`, we know that this corresponds to `airplane`. # Here we use internal utility functions, but anything that returns a # dictionary mapping integers to appropriate string labels would be fine 
label_map = label_map_util.load_labelmap(PATH_TO_LABELS) 
categories = label_map_util.convert_label_map_to_categories(label_map,  max_num_classes=NUM_CLASSES, use_display_name=True) 
category_index = label_map_util.create_category_index(categories) 
# Load the Tensorflow model into memory. 
detection_graph = tf.Graph() 
with detection_graph.as_default(): 
 od_graph_def = tf.GraphDef() 
 with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid: 
 serialized_graph = fid.read() 
 od_graph_def.ParseFromString(serialized_graph) 
 tf.import_graph_def(od_graph_def, name='') 
 sess = tf.Session(graph=detection_graph) 
# Define input and output tensors (i.e. data) for the object detection  classifier 
# Input tensor is the image 
image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')
# Output tensors are the detection boxes, scores, and classes # Each box represents a part of the image where a particular object was  detected 
detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0') 
# Each score represents level of confidence for each of the objects. # The score is shown on the result image, together with the class label. detection_scores = detection_graph.get_tensor_by_name('detection_scores:0') detection_classes =  
detection_graph.get_tensor_by_name('detection_classes:0') 
# Number of objects detected 
num_detections = detection_graph.get_tensor_by_name('num_detections:0') 
#-------------------Initialize other parameters-----------------# # Initialize frame rate calculation 
frame_rate_calc = 1 
freq = cv2.getTickFrequency() 
font = cv2.FONT_HERSHEY_SIMPLEX 
# Define inside box coordinates (top left and bottom right) TL_inside = (int(IM_WIDTH*0.1),int(IM_HEIGHT*0.35)) 
BR_inside = (int(IM_WIDTH*0.45),int(IM_HEIGHT-5)) 
# Define outside box coordinates (top left and bottom right) TL_outside = (int(IM_WIDTH*0.46),int(IM_HEIGHT*0.25)) 
BR_outside = (int(IM_WIDTH*0.8),int(IM_HEIGHT*.85)) 
# Initialize control variables used for pet detector 
detected_inside = False 
detected_outside = False 
inside_counter = 0 
outside_counter = 0 
pause = 0 
pause_counter = 0 
#------------------------- Pet detection function ------------------------- -# 
# This function contains the code to detect a pet, determine if it's # inside or outside, and send a text to the user's phone. def pet_detector(frame): 
 # Use globals for the control variables so they retain their value  after function exits 
 global detected_inside, detected_outside 
 global inside_counter, outside_counter 
 global pause, pause_counter 
 frame_expanded = np.expand_dims(frame, axis=0) 
 # Perform the actual detection by running the model with the image as  input 
 (boxes, scores, classes, num) = sess.run( 
 [detection_boxes, detection_scores, detection_classes,  num_detections],
 feed_dict={image_tensor: frame_expanded}) 
 # Draw the results of the detection (aka 'visulaize the results')  vis_util.visualize_boxes_and_labels_on_image_array( 
 frame, 
 np.squeeze(boxes), 
 np.squeeze(classes).astype(np.int32), 
 np.squeeze(scores), 
 category_index, 
 use_normalized_coordinates=True, 
 line_thickness=8, 
 min_score_thresh=0.40) 
 # Draw boxes defining "outside" and "inside" locations.  cv2.rectangle(frame,TL_outside,BR_outside,(255,20,20),3)  cv2.putText(frame,"Outside box",(TL_outside[0]+10,TL_outside[1]- 10),font,1,(255,20,255),3,cv2.LINE_AA) 
 cv2.rectangle(frame,TL_inside,BR_inside,(20,20,255),3)  cv2.putText(frame,"Inside box",(TL_inside[0]+10,TL_inside[1]- 10),font,1,(20,255,255),3,cv2.LINE_AA) 
  
 # Check the class of the top detected object by looking at  classes[0][0]. 
 # If the top detected object is a cat (17) or a dog (18) (or a teddy  bear (88) for test purposes), 
 # find its center coordinates by looking at the boxes[0][0] variable.  # boxes[0][0] variable holds coordinates of detected objects as (ymin,  xmin, ymax, xmax) 
 if (((int(classes[0][0]) == 17) or (int(classes[0][0] == 18))) and  (pause == 0)): 
 x = int(((boxes[0][0][1]+boxes[0][0][3])/2)*IM_WIDTH)  y = int(((boxes[0][0][0]+boxes[0][0][2])/2)*IM_HEIGHT) 
 # Draw a circle at center of object 
 cv2.circle(frame,(x,y), 5, (75,13,180), -1) 
 # If object is in inside box, increment inside counter variable  if ((x > TL_inside[0]) and (x < BR_inside[0]) and (y > TL_inside[1])  and (y < BR_inside[1])): 
 inside_counter = inside_counter + 1 
 # If object is in outside box, increment outside counter variable  if ((x > TL_outside[0]) and (x < BR_outside[0]) and (y >  TL_outside[1]) and (y < BR_outside[1])): 
 outside_counter = outside_counter + 1 
 # If pet has been detected inside for more than 10 frames, set  detected_inside flag 
 # and send a text to the phone. 
 if inside_counter > 10: 
 detected_inside = True 
 message = client.messages.create( 
 body = 'Your pet wants outside. The door will open soon!',  from_=twilio_number, 
 to=my_number 
 ) 
 inside_counter = 0 
 outside_counter = 0 
 # Pause pet detection by setting "pause" flag 
 pause = 1
 # If pet has been detected outside for more than 10 frames, set  detected_outside flag 
 # and send a text to the phone. 
 if outside_counter > 10: 
 detected_outside = True 
  
 file =  
open('/home/pi/tensorflow1/models/research/object_detection/distance.txt',  'r') 
 distance = file.read() 
 print(distance) 
  
  
 #a='your pets wants inside. The door will open soon! Exercising of  your pet %d'%distance 
  
 message = client.messages.create( 
  
 body = 'Your pet wants inside. The door will open soon!  Exercising of your pet', 
 from_= twilio_number, 
 to = my_number 
 ) 
 # file =  
open('/home/pi/tensorflow1/models/research/object_detection/distance.txt',  'r') 
 # distance = file.read() 
 # print(distance) 
  
 file.close() 
  
 inside_counter = 0 
 outside_counter = 0 
 # Pause pet detection by setting "pause" flag 
 pause = 1 
  
 # If pause flag is set, draw message on screen. 
 if pause == 1: 
  
 if detected_inside == True: 
 cv2.putText(frame,'Pet wants  
outside!',(int(IM_WIDTH*.1),int(IM_HEIGHT*.5)),font,2,(0,0,0),5,cv2.LINE_AA ) 
 cv2.putText(frame,'Pet wants  
outside!',(int(IM_WIDTH*.1),int(IM_HEIGHT*.5)),font,2,(95,176,23),3,cv2.LIN E_AA) 
  
 if detected_outside == True: 
 cv2.putText(frame,'Pet wants  
inside!',(int(IM_WIDTH*.1),int(IM_HEIGHT*.5)),font,2,(0,0,0),5,cv2.LINE_AA)  cv2.putText(frame,'Pet wants  
inside!',(int(IM_WIDTH*.1),int(IM_HEIGHT*.5)),font,2,(95,176,23),3,cv2.LINE _AA) 
  
cv2.putText(frame,str(distance),(int(TL_outside[0]+300),int(60)),font,2,(0, 0,255),3,cv2.LINE_AA) 
 
  
 servo1.start(0) 
 servo2.start(0) 
 servo2.ChangeDutyCycle(5.5) 
 sleep(0.1) 
 servo1.ChangeDutyCycle(5.2) 
 sleep(0.1) 
 servo2.ChangeDutyCycle(0) 
 sleep(0.1) 
 servo1.ChangeDutyCycle(0) 
 sleep(5) 
 servo2.ChangeDutyCycle(8.6) 
 sleep(0.1) 
 servo1.ChangeDutyCycle(9.0) 
 sleep(0.1) 
 servo2.ChangeDutyCycle(0) 
 sleep(0.1) 
 servo1.ChangeDutyCycle(0) 
  
 servo1.stop() 
 servo2.stop() 
 GPIO.cleanup() 
  
  
 # Increment pause counter until it reaches 30 (for a framerate of  1.5 FPS, this is about 20 seconds), 
 # then unpause the application (set pause flag to 0).  pause_counter = pause_counter + 1 
 if pause_counter > 5: 
 pause = 0 
 pause_counter = 0 
 detected_inside = False 
 detected_outside = False 
 # Draw counter info 
 cv2.putText(frame,'Detection counter: ' +  
str(max(inside_counter,outside_counter)),(10,100),font,0.5,(255,255,0),1,cv 2.LINE_AA) 
 cv2.putText(frame,'Pause counter: ' +  
str(pause_counter),(10,150),font,0.5,(255,255,0),1,cv2.LINE_AA)  return frame 
#### Initialize camera and perform object detection #### 
### Picamera ### 
if camera_type == 'picamera': 
 # Initialize Picamera and grab reference to the raw capture  camera = PiCamera() 
 camera.resolution = (IM_WIDTH,IM_HEIGHT) 
 camera.framerate = 10 
 rawCapture = PiRGBArray(camera, size=(IM_WIDTH,IM_HEIGHT))  rawCapture.truncate(0) 
 # Continuously capture frames and perform object detection on them  for frame1 in camera.capture_continuous(rawCapture,  
format="bgr",use_video_port=True):
 t1 = cv2.getTickCount() 
  
 # Acquire frame and expand frame dimensions to have shape: [1, None,  None, 3] 
 # i.e. a single-column array, where each item in the column has the  pixel RGB value 
 frame = np.copy(frame1.array) 
 frame.setflags(write=1) 
 # Pass frame into pet detection function 
 frame = pet_detector(frame) 
 # Draw FPS 
 cv2.putText(frame,"FPS:  
{0:.2f}".format(frame_rate_calc),(30,50),font,1,(255,255,0),2,cv2.LINE_AA) 
 # All the results have been drawn on the frame, so it's time to  display it. 
 cv2.imshow('Object detector', frame) 
 # FPS calculation 
 t2 = cv2.getTickCount() 
 time1 = (t2-t1)/freq 
 frame_rate_calc = 1/time1 
 # Press 'q' to quit 
 if cv2.waitKey(1) == ord('q'): 
 break 
 rawCapture.truncate(0) 
 camera.close() 
cv2.destroyAllWindows()
